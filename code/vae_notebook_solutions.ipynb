{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to implement a Variational Autoencoder (VAE)\n",
    "\n",
    "A variational autoencoder observes data, infers a latent code for it and tries to reconstruct the data from that latent code. In contrast to regular autoencoders, the code of the VAE is **random**. That means that when presented with the same input, the VAE will produce a slightly different code each time. This makes its decoding process more robust, since it has to deal with noisy code.\n",
    "\n",
    "Another way of looking at a VAE is as a training procedure for a probablistic model. The model is \n",
    "$$p(x) = \\int p(z)p(x|z) dz$$\n",
    "where $z$ is the latent code and $x$ is the data. During training we need to infer a posterior over $z$. In the case of a VAE this is done by neural network.\n",
    "\n",
    "Assuming that the theory of VAEs has already been presented, we now dive straight into implementing them. If you need more background on VAEs, have a look at our [tutorial slides](https://github.com/philschulz/VITutorial/tree/master/modules) and the references therein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Framework\n",
    "\n",
    "For the purpose of this tutorial we are going to use [mxnet](https://mxnet.incubator.apache.org) which is a scalable deep learning library that has interfaces for several languages, including python. We are going to import and abbreviate it as \"mx\". We will use mxnet to define computation graph. This is done using the [symbol library](https://mxnet.incubator.apache.org/api/python/symbol.html). When building the VAE, all the methods that you use should be prefixed with `mx.sym`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import urllib.request\n",
    "import os, logging, sys\n",
    "from os.path import join, exists\n",
    "from abc import ABC\n",
    "from typing import List, Tuple, Callable\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify a couple of constants that will help us to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LEARNING_RATE = 0.0003\n",
    "\n",
    "TRAIN_SET = 'train'\n",
    "VALID_SET = 'valid'\n",
    "TEST_SET = 'test'\n",
    "data_names = [TRAIN_SET, VALID_SET, TEST_SET]\n",
    "test_set = [TEST_SET]\n",
    "data_dir = join(os.curdir, \"binary_mnist\")\n",
    "\n",
    "# change this to mx.gpu(0) if you want to run your code on gpu\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up basic logging facilities to print intermediate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s [%(levelname)s]: %(message)s\", datefmt=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Throughout the tutorial we will use the binarised MNIST data set consisting of images of handwritten digits (0-9). Each pixel has been mapped to either 0 or 1, meaning that pixels are either fully on or off. We use this data set because it allows us to use a rather simple product of Bernoullis as a likelihood. We download the data into a folder called \"binary_mnist\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:56:19 [INFO]: Data file binary_mnist.train exists\n",
      "10:56:19 [INFO]: Data file binary_mnist.valid exists\n",
      "10:56:19 [INFO]: Data file binary_mnist.test exists\n"
     ]
    }
   ],
   "source": [
    "if not exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "for data_set in data_names:\n",
    "    file_name = \"binary_mnist.{}\".format(data_set)\n",
    "    goal = join(data_dir, file_name)\n",
    "    if exists(goal):\n",
    "        logging.info(\"Data file {} exists\".format(file_name))\n",
    "    else:\n",
    "        logging.info(\"Downloading {}\".format(file_name))\n",
    "        link = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_{}.amat\".format(\n",
    "            data_set)\n",
    "        urllib.request.urlretrieve(link, goal)\n",
    "        logging.info(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we have the data on disk. We will load it later for training and testing. But first, we need to build our VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonal Gaussian VAE\n",
    "\n",
    "The most basic VAE model is one where we assume that the latent variable is multiviariate Gaussian. We fix the prior to be standard normal. During inference, we use a multivariate Gaussian variational distribution with diagonal covariance matrix. This means that we are only modelling variance but not covariance (in fact, a k-dimensional Guassian with diagonal covariance has the same density as a product of k independent univariate Gaussians). Geometrically, this variational distribution can only account for spherical but not for eliptical densities. It is thus rather limited in its modelling capabilities. Still, because it uses a neural network under the hood, it is very expressive. \n",
    "\n",
    "In this tutorial, we will model the mist binarised digit data set. Each image is encoded as a 784-dimensional vector. We will model each of these vectors as a product of 784 Bernoullis (of course, there are better models but we want to keep it simple). Our likelihood is thus a product of independent Bernoullis. The resulting model is formally specified as \n",
    "\n",
    "\\begin{align}z \\sim \\mathcal{N}(0,I) && x_i|z \\sim Bernoulli(NN_{\\theta}(z))~~~ i \\in \\{1,2,\\ldots, 784\\} \\ .\\end{align}\n",
    "\n",
    "The variational approximation is given by $$q(z|x) = \\mathcal{N}(NN_{\\lambda}(x), NN_{\\lambda}(x)).$$\n",
    "\n",
    "Notice that both the Bernoulli likelihood and the Gaussian variational distribution use NNs to compute their parameters. The parameters of the NNs, however, are different ($\\theta$ and $\\lambda$, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We will spread our implementation across 3 classes. This design choice is motivated by the desire to make our models as modular as possible. This will later allow us to mix and match different likelihoods and variational distributions.\n",
    "\n",
    "* **Generator**: This class defines our likelihood. Given a latent value, it will can produce a data sample our assign a density to an existing data point.\n",
    "* **InferenceNetwork**: This neural network computes the parameters of the variational approximation from a data point.\n",
    "* **VAE**: This is the variational autoencoder. It combines a Generator and an InferenceNetwork and trains them jointly. Once trained, it can generate random data points or try to reproduce data presented to it.\n",
    "\n",
    "Below we have specified these classes abstractly. Make sure you understand what each method is supposed to be doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(ABC):\n",
    "    \"\"\"\n",
    "    Generator network.\n",
    "\n",
    "    :param data_dims: Dimensionality of the generated data.\n",
    "    :param layer_sizes: Size of each layer in the network.\n",
    "    :param act_type: The activation after each layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dims: int, layer_sizes: List[int], act_type: str) -> None:\n",
    "        self.data_dims = data_dims\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.act_type = act_type\n",
    "\n",
    "    def generate_sample(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate a data sample from a latent state.\n",
    "\n",
    "        :param latent_state: The latent input state.\n",
    "        :return: A data sample.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def train(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator from a given latent state.\n",
    "        \n",
    "        :param latent_state: The latent input state\n",
    "        :return: The loss symbol used for training\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        \n",
    "class InferenceNetwork(ABC):\n",
    "    \"\"\"\n",
    "    A network to infer distributions over latent states.\n",
    "\n",
    "    :param latent_variable_size: The dimensionality of the latent variable.\n",
    "    :param layer_sizes: Size of each layer in the network.\n",
    "    :param act_type: The activation after each layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_variable_size: int, layer_sizes: List[int], act_type: str) -> None:\n",
    "        self.latent_var_size = latent_variable_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.act_type = act_type\n",
    "\n",
    "    def inference(self, data: mx.sym.Symbol) -> Tuple[mx.sym.Symbol, ...]:\n",
    "        \"\"\"\n",
    "        Infer the parameters of the distribution over latent values.\n",
    "\n",
    "        :param data: A data sample.\n",
    "        :return: The parameters of the distribution.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "class VAE(ABC):\n",
    "    \"\"\"\n",
    "    A variational autoencoding model (Kingma and Welling, 2013).\n",
    "\n",
    "    :param generator: A generator network that specifies the likelihood of the model.\n",
    "    :param inference_net: An inference network that specifies the distribution over latent values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generator: Generator, inference_net: InferenceNetwork) -> None:\n",
    "        self.generator = generator\n",
    "        self.inference_net = inference_net\n",
    "\n",
    "    def train(self, data: mx.sym.Symbol, label: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator and inference network jointly by optimising the ELBO.\n",
    "\n",
    "        :param data: The training data.\n",
    "        :param label: Copy of the training data.\n",
    "        :return: A list of loss symbols.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def generate_reconstructions(self, data: mx.sym.Symbol, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate a number of reconstructions of input data points.\n",
    "\n",
    "        :param data: The input data.\n",
    "        :param n: Number of reconstructions per data point.\n",
    "        :return: The reconstructed data.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def phantasize(self, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate data by randomly sampling from the prior.\n",
    "\n",
    "        :param n: Number of sampled data points.\n",
    "        :return: Randomly generated data points.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Let us start by implementing the generator. This is pretty much a standard neural network. The main point of this exercise is to get you comfortable with mxnet. Complete all the TODOs below. Before starting, check mxnet's [fully connected layer](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.FullyConnected) and [activation functions](https://mxnet.incubator.apache.org/api/python/symbol.html#mxnet.symbol.Activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductOfBernoullisGenerator(Generator):\n",
    "    \"\"\"\n",
    "    A generator that produces binary vectors whose entries are independent Bernoulli draws.\n",
    "\n",
    "    :param data_dims: Dimensionality of the generated data.\n",
    "    :param layer_sizes: Size of each layer in the network.\n",
    "    :param act_type: The activation after each layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dims: int, layer_sizes=List[int], act_type=str) -> None:\n",
    "        super().__init__(data_dims, layer_sizes, act_type)\n",
    "        # TODO choose the correct output activation for a Bernoulli variable. This should just be a string.\n",
    "        self.output_act = \"sigmoid\"\n",
    "\n",
    "    def _preactivation(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Computes the pre-activation of the generator, i.e. the hidden state before the final output activation.\n",
    "\n",
    "        :param latent_state: The input latent state\n",
    "        :return: The pre-activation before output activation\n",
    "        \"\"\"\n",
    "        prev_out = latent_state\n",
    "        for i, hidden in enumerate(self.layer_sizes):\n",
    "            fc_i = mx.sym.FullyConnected(data=prev_out, num_hidden=hidden, name=\"gen_fc_{}\".format(i))\n",
    "            act_i = mx.sym.Activation(data=fc_i, act_type=self.act_type, name=\"gen_act_{}\".format(i))\n",
    "            prev_out = act_i\n",
    "\n",
    "        # The output layer that gives pre_activations for multiple Bernoulli softmax between 0 and 1\n",
    "        fc_out = mx.sym.FullyConnected(data=prev_out, num_hidden=2 * self.data_dims, name=\"gen_fc_out\")\n",
    "\n",
    "        return fc_out\n",
    "    \n",
    "    def generate_sample(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generates a data sample by picking producing the maximally likely outcome. The stochasticity in the sampling\n",
    "        process comes from the latent_state.\n",
    "\n",
    "        :param latent_state: The input latent state.\n",
    "        :return: A vector of Bernoulli draws.\n",
    "        \"\"\"\n",
    "        act = mx.sym.Activation(data=self._generate(latent_state=latent_state), act_type=self.output_act,\n",
    "                                name=\"gen_act_out\")\n",
    "        out = act > 0.5\n",
    "        return out\n",
    "\n",
    "        return out\n",
    "\n",
    "    def train(self, latent_state=mx.sym.Symbol, label=mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator from a given latent state\n",
    "\n",
    "        :param latent_state: The input latent state\n",
    "        :param label: A binary vector (same as input for inference module)\n",
    "        :return: The loss symbol used for training\n",
    "        \"\"\"\n",
    "        output = mx.sym.Activation(data=self._preactivation(latent_state=latent_state), act_type=self.output_act,\n",
    "                                   name=\"output_act\")\n",
    "        return mx.sym.sum(label * mx.sym.log(output) + (1-label) * mx.sym.log(1-output), axis=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "We now move on to the inference network. Recall that this network will return the parameters of a diagonal Gaussian. Thus, we need to return to vectors of the same size: a mean and a standard deviation vector. (Formally, the parameters of the Gaussian are the variances. However, from the derivation of the Gaussian reparametrisation we know that we\n",
    "need the standard deviations to generate a Gaussian random variable $z$ as transformation of a standard Gaussian variable $\\epsilon$.)\n",
    "\n",
    "**Hint:** In this exercise you will need to draw a random Gaussian sample (see [here](https://mxnet.incubator.apache.org/api/python/symbol.html#mxnet.symbol.random_normal)). The operator requires are\n",
    "shape whose first entry is the batch size. The batch size is not known to you during implementation, however.\n",
    "You can leave it underspecified by choosing $0$ as a value. When you combine the sampling operator with another\n",
    "operator immediately, mxnet will infer the correct the batch size for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianInferenceNetwork(InferenceNetwork):\n",
    "    \"\"\"\n",
    "    An inference network that predicts the parameters of a diagonal Gaussian and samples from that distribution.\n",
    "\n",
    "    :param latent_variable_size: The dimensionality of the latent variable.\n",
    "    :param layer_sizes: Size of each layer in the network.\n",
    "    :param act_type: The activation after each layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_variable_size: int, layer_sizes: List[int], act_type: str):\n",
    "        super().__init__(latent_variable_size, layer_sizes, act_type)\n",
    "\n",
    "    def inference(self, data: mx.sym.Symbol) -> Tuple[mx.sym.Symbol, mx.sym.Symbol]:\n",
    "        \"\"\"\n",
    "        Infer the mean and standard deviation.\n",
    "\n",
    "        :param data: A data sample.\n",
    "        :return: The mean and standard deviation.\n",
    "        \"\"\"\n",
    "        # We choose to share the first layer between the networks that compute the standard deviations\n",
    "        # and means. This is a fairly standard design choice.\n",
    "        shared_layer = mx.sym.FullyConnected(data=data, num_hidden=self.layer_sizes[0], name=\"inf_joint_fc\")\n",
    "        shared_layer = mx.sym.Activation(data=shared_layer, act_type=self.act_type, name=\"inf_joint_act\")\n",
    "\n",
    "        prev_out = shared_layer\n",
    "        for i, size in enumerate(self.layer_sizes[1:]):\n",
    "            mean_fc_i = mx.sym.FullyConnected(data=prev_out, num_hidden=size, name=\"inf_mean_fc_{}\".format(i))\n",
    "            mean_act_i = mx.sym.Activation(data=mean_fc_i, act_type=self.act_type, name=\"inf_mean_act_{}\".format(i))\n",
    "            prev_out = mean_act_i\n",
    "        mean = mx.sym.FullyConnected(data=prev_out, num_hidden=self.latent_var_size, name=\"inf_mean_compute\")\n",
    "\n",
    "        prev_out = shared_layer\n",
    "        for i, size in enumerate(self.layer_sizes[1:]):\n",
    "            var_fc_i = mx.sym.FullyConnected(data=prev_out, num_hidden=size, name=\"rec_var_fc_{}\".format(i))\n",
    "            var_act_i = mx.sym.Activation(data=var_fc_i, act_type=self.act_type, name=\"rec_var_act_{}\".format(i))\n",
    "            prev_out = var_act_i\n",
    "        # soft-relu maps std onto non-negative real line\n",
    "        std = mx.sym.Activation(\n",
    "            mx.sym.FullyConnected(data=prev_out, num_hidden=self.latent_var_size, name=\"inf_var_compute\"),\n",
    "            act_type=\"softrelu\")\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "    def sample_latent_state(self, mean: mx.sym.Symbol, std: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Sample a latent Gaussian variable\n",
    "\n",
    "        :param mean: The mean of the Gaussian\n",
    "        :param std: The standard deviation of the Gaussian\n",
    "        :return: A Gaussian sample\n",
    "        \"\"\"\n",
    "        # TODO: This is where the magic happens! Draw a sample from the Gaussian using the Gaussian reparametrisation\n",
    "        # trick and return it.\n",
    "        return mean + std * mx.sym.random_normal(loc=0, scale=1, shape=(0, self.latent_var_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.a\n",
    "\n",
    "Finally, we will put it all together and build our VAE. Recall that the objective for the inference net contains a KL term. You will need to implement that KL-term. Once it is implemented, we can take advantage of autograd to get its gradients. Use the [log](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.log) and [sum](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.sum) symbols here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagonal_gaussian_kl(mean: mx.sym.Symbol, std: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "    var = std ** 2\n",
    "    return -0.5 * mx.sym.sum(data=1 + mx.sym.log(var) - mean ** 2 - var, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.b\n",
    "\n",
    "The only thing that is left to do is to implement VAE training. To train our VAE we will maximise the ELBO:\n",
    "$$ \\mathbb{E}\\left[ \\log p(x|z) \\right] - \\text{KL}(q(z)||p(z) \\. $$\n",
    "Recall that we assume that $ p(z) = \\mathcal{N}(z;0,I) $. Mxnet's optimisers minimise losses instead of maximising objectives. We thus turn the ELBO into a loss by taking its negative. Losses in mxnet are defined using the [MakeLoss](https://mxnet.incubator.apache.org/api/python/symbol.html#mxnet.symbol.MakeLoss) symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianVAE(VAE):\n",
    "    \"\"\"\n",
    "    A VAE with Gaussian latent variables. It assumes a standard normal prior on the latent values.\n",
    "\n",
    "    :param generator: A generator network that specifies the likelihood of the model.\n",
    "    :param inference_net: An inference network that specifies the Gaussian over latent values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 generator: Generator,\n",
    "                 inference_net: GaussianInferenceNetwork,\n",
    "                 kl_divergence: Callable) -> None:\n",
    "        self.generator = generator\n",
    "        self.inference_net = inference_net\n",
    "        self.kl_divergence = kl_divergence\n",
    "\n",
    "    def train(self, data: mx.sym.Symbol, label: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator and inference network jointly by optimising the ELBO.\n",
    "\n",
    "        :param data: The training data.\n",
    "        :param label: Copy of the training data.\n",
    "        :return: A list of loss symbols.\n",
    "        \"\"\"\n",
    "        mean, std = self.inference_net.inference(data=data)\n",
    "        latent_state = self.inference_net.sample_latent_state(mean, std)\n",
    "        kl_term = self.kl_divergence(mean, std)\n",
    "        log_likelihood = self.generator.train(latent_state=latent_state, label=label)\n",
    "        return mx.sym.MakeLoss(kl_term - log_likelihood)\n",
    "\n",
    "    def generate_reconstructions(self, data: mx.sym.Symbol, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate a number of reconstructions of input data points.\n",
    "\n",
    "        :param data: The input data.\n",
    "        :param n: Number of reconstructions per data point.\n",
    "        :return: The reconstructed data.\n",
    "        \"\"\"\n",
    "        mean, std = self.inference_net.inference(data=data)\n",
    "        mean = mx.sym.tile(data=mean, reps=(n, 1))\n",
    "        std = mx.sym.tile(data=std, reps=(n, 1))\n",
    "        latent_state = self.sample_latent_state(mean, std, n)\n",
    "        return self.generator.generate_sample(latent_state=latent_state)\n",
    "\n",
    "    def phantasize(self, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate data by randomly sampling from the prior.\n",
    "\n",
    "        :param n: Number of sampled data points.\n",
    "        :return: Randomly generated data points.\n",
    "        \"\"\"\n",
    "        latent_state = mx.sym.random_normal(loc=0, scale=1, shape=(n, self.inference_net.latent_var_size))\n",
    "        return self.generator.generate_sample(latent_state=latent_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a VAE\n",
    "\n",
    "We have now all the code for VAEs in place. Below, we have defined a factory method that makes it easier for you to play with different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vae(latent_type: str,\n",
    "                  likelihood: str,\n",
    "                  generator_layer_sizes: List[int],\n",
    "                  infer_layer_sizes: List[int],\n",
    "                  latent_variable_size: int,\n",
    "                  data_dims: int,\n",
    "                  generator_act_type: str = \"tanh\",\n",
    "                  infer_act_type: str = \"tanh\") -> VAE:\n",
    "    \"\"\"\n",
    "    Construct a variational autoencoder\n",
    "\n",
    "    :param latent_type: Distribution of latent variable.\n",
    "    :param likelihood: Type of likelihood.\n",
    "    :param generator_layer_sizes: Sizes of generator hidden layers.\n",
    "    :param infer_layer_size: Sizes of inference network hidden layers.\n",
    "    :param latent_variable_size: Size of the latent variable.\n",
    "    :param data_dims: Dimensionality of the data.\n",
    "    :param generator_act_type: Activation function for generator hidden layers.\n",
    "    :param infer_act_type: Activation function for inference network hidden layers.\n",
    "    :return: A variational autoencoder.\n",
    "    \"\"\"\n",
    "    if likelihood == \"bernoulliProd\":\n",
    "        generator = ProductOfBernoullisGenerator(data_dims=data_dims, layer_sizes=generator_layer_sizes,\n",
    "                                                 act_type=generator_act_type)\n",
    "    else:\n",
    "        raise Exception(\"{} is an invalid likelihood type.\".format(likelihood))\n",
    "\n",
    "    if latent_type == \"gaussian\":\n",
    "        inference_net = GaussianInferenceNetwork(latent_variable_size=latent_variable_size,\n",
    "                                                 layer_sizes=infer_layer_sizes,\n",
    "                                                 act_type=infer_act_type)\n",
    "        return GaussianVAE(generator=generator, inference_net=inference_net, kl_divergence=diagonal_gaussian_kl)\n",
    "    else:\n",
    "        raise Exception(\"{} is an invalid latent variable type.\".format(latent_type))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "Your turn! Construct your own VAE below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = construct_vae(latent_type=\"gaussian\", likelihood=\"bernoulliProd\", generator_layer_sizes=[200,500],\n",
    "                   infer_layer_sizes=[500,200], latent_variable_size=200, data_dims=784, generator_act_type=\"tanh\",\n",
    "                   infer_act_type=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what your VAE looks like we will visualise it. The variables are \"data\" and \"label\" are unbound variables in the computation graph. We will shortly use them to supply data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"364pt\" height=\"1758pt\"\n",
       " viewBox=\"0.00 0.00 363.68 1758.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1754)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1754 359.685,-1754 359.685,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"144.685\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.685\" y=\"-25.3\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- inf_joint_fc -->\n",
       "<g id=\"node2\" class=\"node\"><title>inf_joint_fc</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"191.685,-152 97.6846,-152 97.6846,-94 191.685,-94 191.685,-152\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.685\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"144.685\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">500</text>\n",
       "</g>\n",
       "<!-- inf_joint_fc&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>inf_joint_fc&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.685,-83.7443C144.685,-75.2043 144.685,-66.2977 144.685,-58.2479\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.685,-93.8971 140.185,-83.897 144.685,-88.8971 144.685,-83.8971 144.685,-83.8971 144.685,-83.8971 144.685,-88.8971 149.185,-83.8971 144.685,-93.8971 144.685,-93.8971\"/>\n",
       "</g>\n",
       "<!-- inf_joint_act -->\n",
       "<g id=\"node3\" class=\"node\"><title>inf_joint_act</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"191.685,-246 97.6846,-246 97.6846,-188 191.685,-188 191.685,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.685\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"144.685\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- inf_joint_act&#45;&gt;inf_joint_fc -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>inf_joint_act&#45;&gt;inf_joint_fc</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.685,-177.744C144.685,-169.204 144.685,-160.298 144.685,-152.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.685,-187.897 140.185,-177.897 144.685,-182.897 144.685,-177.897 144.685,-177.897 144.685,-177.897 144.685,-182.897 149.185,-177.897 144.685,-187.897 144.685,-187.897\"/>\n",
       "</g>\n",
       "<!-- rec_var_fc_0 -->\n",
       "<g id=\"node4\" class=\"node\"><title>rec_var_fc_0</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"149.685,-340 55.6846,-340 55.6846,-282 149.685,-282 149.685,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.685\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"102.685\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\">200</text>\n",
       "</g>\n",
       "<!-- rec_var_fc_0&#45;&gt;inf_joint_act -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>rec_var_fc_0&#45;&gt;inf_joint_act</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M119.764,-272.588C123.779,-263.793 127.993,-254.563 131.789,-246.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.514,-281.897 115.574,-270.931 117.591,-277.349 119.667,-272.8 119.667,-272.8 119.667,-272.8 117.591,-277.349 123.761,-274.669 115.514,-281.897 115.514,-281.897\"/>\n",
       "</g>\n",
       "<!-- rec_var_act_0 -->\n",
       "<g id=\"node5\" class=\"node\"><title>rec_var_act_0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"131.685,-434 37.6846,-434 37.6846,-376 131.685,-376 131.685,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- rec_var_act_0&#45;&gt;rec_var_fc_0 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>rec_var_act_0&#45;&gt;rec_var_fc_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.1143,-366.026C93.8019,-357.4 95.5655,-348.386 97.1578,-340.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.183,-375.897 87.6869,-365.219 91.1431,-370.99 92.1032,-366.083 92.1032,-366.083 92.1032,-366.083 91.1431,-370.99 96.5194,-366.947 90.183,-375.897 90.183,-375.897\"/>\n",
       "</g>\n",
       "<!-- inf_var_compute -->\n",
       "<g id=\"node6\" class=\"node\"><title>inf_var_compute</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"131.685,-528 37.6846,-528 37.6846,-470 131.685,-470 131.685,-528\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-502.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-487.8\" font-family=\"Times,serif\" font-size=\"14.00\">200</text>\n",
       "</g>\n",
       "<!-- inf_var_compute&#45;&gt;rec_var_act_0 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>inf_var_compute&#45;&gt;rec_var_act_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6846,-459.744C84.6846,-451.204 84.6846,-442.298 84.6846,-434.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.6846,-469.897 80.1847,-459.897 84.6846,-464.897 84.6847,-459.897 84.6847,-459.897 84.6847,-459.897 84.6846,-464.897 89.1847,-459.897 84.6846,-469.897 84.6846,-469.897\"/>\n",
       "</g>\n",
       "<!-- activation0 -->\n",
       "<g id=\"node7\" class=\"node\"><title>activation0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"131.685,-622 37.6846,-622 37.6846,-564 131.685,-564 131.685,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-596.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-581.8\" font-family=\"Times,serif\" font-size=\"14.00\">softrelu</text>\n",
       "</g>\n",
       "<!-- activation0&#45;&gt;inf_var_compute -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>activation0&#45;&gt;inf_var_compute</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6846,-553.744C84.6846,-545.204 84.6846,-536.298 84.6846,-528.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.6846,-563.897 80.1847,-553.897 84.6846,-558.897 84.6847,-553.897 84.6847,-553.897 84.6847,-553.897 84.6846,-558.897 89.1847,-553.897 84.6846,-563.897 84.6846,-563.897\"/>\n",
       "</g>\n",
       "<!-- _powerscalar0 -->\n",
       "<g id=\"node8\" class=\"node\"><title>_powerscalar0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"131.685,-716 37.6846,-716 37.6846,-658 131.685,-658 131.685,-716\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-683.3\" font-family=\"Times,serif\" font-size=\"14.00\">_powerscalar0</text>\n",
       "</g>\n",
       "<!-- _powerscalar0&#45;&gt;activation0 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>_powerscalar0&#45;&gt;activation0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6846,-647.744C84.6846,-639.204 84.6846,-630.298 84.6846,-622.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.6846,-657.897 80.1847,-647.897 84.6846,-652.897 84.6847,-647.897 84.6847,-647.897 84.6847,-647.897 84.6846,-652.897 89.1847,-647.897 84.6846,-657.897 84.6846,-657.897\"/>\n",
       "</g>\n",
       "<!-- log0 -->\n",
       "<g id=\"node9\" class=\"node\"><title>log0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"131.685,-810 37.6846,-810 37.6846,-752 131.685,-752 131.685,-810\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-777.3\" font-family=\"Times,serif\" font-size=\"14.00\">log0</text>\n",
       "</g>\n",
       "<!-- log0&#45;&gt;_powerscalar0 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>log0&#45;&gt;_powerscalar0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6846,-741.744C84.6846,-733.204 84.6846,-724.298 84.6846,-716.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.6846,-751.897 80.1847,-741.897 84.6846,-746.897 84.6847,-741.897 84.6847,-741.897 84.6847,-741.897 84.6846,-746.897 89.1847,-741.897 84.6846,-751.897 84.6846,-751.897\"/>\n",
       "</g>\n",
       "<!-- _plusscalar0 -->\n",
       "<g id=\"node10\" class=\"node\"><title>_plusscalar0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"131.685,-904 37.6846,-904 37.6846,-846 131.685,-846 131.685,-904\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-871.3\" font-family=\"Times,serif\" font-size=\"14.00\">_plusscalar0</text>\n",
       "</g>\n",
       "<!-- _plusscalar0&#45;&gt;log0 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>_plusscalar0&#45;&gt;log0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6846,-835.744C84.6846,-827.204 84.6846,-818.298 84.6846,-810.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.6846,-845.897 80.1847,-835.897 84.6846,-840.897 84.6847,-835.897 84.6847,-835.897 84.6847,-835.897 84.6846,-840.897 89.1847,-835.897 84.6846,-845.897 84.6846,-845.897\"/>\n",
       "</g>\n",
       "<!-- inf_mean_fc_0 -->\n",
       "<g id=\"node11\" class=\"node\"><title>inf_mean_fc_0</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"243.685,-434 149.685,-434 149.685,-376 243.685,-376 243.685,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\">200</text>\n",
       "</g>\n",
       "<!-- inf_mean_fc_0&#45;&gt;inf_joint_act -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>inf_mean_fc_0&#45;&gt;inf_joint_act</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.99,-365.746C176.054,-330.206 161.488,-278.104 152.571,-246.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188.787,-375.751 181.761,-367.332 187.441,-370.935 186.094,-366.12 186.094,-366.12 186.094,-366.12 187.441,-370.935 190.428,-364.908 188.787,-375.751 188.787,-375.751\"/>\n",
       "</g>\n",
       "<!-- inf_mean_act_0 -->\n",
       "<g id=\"node12\" class=\"node\"><title>inf_mean_act_0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"243.685,-622 149.685,-622 149.685,-564 243.685,-564 243.685,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-596.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-581.8\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- inf_mean_act_0&#45;&gt;inf_mean_fc_0 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>inf_mean_act_0&#45;&gt;inf_mean_fc_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.685,-553.746C196.685,-518.206 196.685,-466.104 196.685,-434.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.685,-563.751 192.185,-553.751 196.685,-558.751 196.685,-553.751 196.685,-553.751 196.685,-553.751 196.685,-558.751 201.185,-553.751 196.685,-563.751 196.685,-563.751\"/>\n",
       "</g>\n",
       "<!-- inf_mean_compute -->\n",
       "<g id=\"node13\" class=\"node\"><title>inf_mean_compute</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"243.685,-716 149.685,-716 149.685,-658 243.685,-658 243.685,-716\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-690.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-675.8\" font-family=\"Times,serif\" font-size=\"14.00\">200</text>\n",
       "</g>\n",
       "<!-- inf_mean_compute&#45;&gt;inf_mean_act_0 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>inf_mean_compute&#45;&gt;inf_mean_act_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.685,-647.744C196.685,-639.204 196.685,-630.298 196.685,-622.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.685,-657.897 192.185,-647.897 196.685,-652.897 196.685,-647.897 196.685,-647.897 196.685,-647.897 196.685,-652.897 201.185,-647.897 196.685,-657.897 196.685,-657.897\"/>\n",
       "</g>\n",
       "<!-- _powerscalar1 -->\n",
       "<g id=\"node14\" class=\"node\"><title>_powerscalar1</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"243.685,-810 149.685,-810 149.685,-752 243.685,-752 243.685,-810\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.685\" y=\"-777.3\" font-family=\"Times,serif\" font-size=\"14.00\">_powerscalar1</text>\n",
       "</g>\n",
       "<!-- _powerscalar1&#45;&gt;inf_mean_compute -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>_powerscalar1&#45;&gt;inf_mean_compute</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.685,-741.744C196.685,-733.204 196.685,-724.298 196.685,-716.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.685,-751.897 192.185,-741.897 196.685,-746.897 196.685,-741.897 196.685,-741.897 196.685,-741.897 196.685,-746.897 201.185,-741.897 196.685,-751.897 196.685,-751.897\"/>\n",
       "</g>\n",
       "<!-- _minus0 -->\n",
       "<g id=\"node15\" class=\"node\"><title>_minus0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"131.685,-998 37.6846,-998 37.6846,-940 131.685,-940 131.685,-998\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.6846\" y=\"-965.3\" font-family=\"Times,serif\" font-size=\"14.00\">_minus0</text>\n",
       "</g>\n",
       "<!-- _minus0&#45;&gt;_plusscalar0 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>_minus0&#45;&gt;_plusscalar0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6846,-929.744C84.6846,-921.204 84.6846,-912.298 84.6846,-904.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.6846,-939.897 80.1847,-929.897 84.6846,-934.897 84.6847,-929.897 84.6847,-929.897 84.6847,-929.897 84.6846,-934.897 89.1847,-929.897 84.6846,-939.897 84.6846,-939.897\"/>\n",
       "</g>\n",
       "<!-- _minus0&#45;&gt;_powerscalar1 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>_minus0&#45;&gt;_powerscalar1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M119.145,-932.264C126.759,-923.413 134.416,-913.681 140.685,-904 160.19,-873.873 176.493,-835.844 186.388,-810.321\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-939.791 115.744,-929.316 115.809,-936.043 119.118,-932.294 119.118,-932.294 119.118,-932.294 115.809,-936.043 122.491,-935.273 112.5,-939.791 112.5,-939.791\"/>\n",
       "</g>\n",
       "<!-- _minus1 -->\n",
       "<g id=\"node16\" class=\"node\"><title>_minus1</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"130.685,-1092 36.6846,-1092 36.6846,-1034 130.685,-1034 130.685,-1092\"/>\n",
       "<text text-anchor=\"middle\" x=\"83.6846\" y=\"-1059.3\" font-family=\"Times,serif\" font-size=\"14.00\">_minus1</text>\n",
       "</g>\n",
       "<!-- _minus1&#45;&gt;_powerscalar0 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>_minus1&#45;&gt;_powerscalar0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.1793,-1025.93C38.4294,-1017.48 32.3888,-1007.99 28.6846,-998 -9.31411,-895.482 -9.77088,-854.347 28.6846,-752 33.6698,-738.732 42.7911,-726.415 52.2454,-716.202\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.8151,-1033.7 41.9001,-1029.02 48.5689,-1029.9 45.3227,-1026.1 45.3227,-1026.1 45.3227,-1026.1 48.5689,-1029.9 48.7454,-1023.18 51.8151,-1033.7 51.8151,-1033.7\"/>\n",
       "</g>\n",
       "<!-- _minus1&#45;&gt;_minus0 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>_minus1&#45;&gt;_minus0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.1004,-1023.74C84.1932,-1015.2 84.29,-1006.3 84.3775,-998.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.99,-1033.9 79.5991,-1023.85 84.0444,-1028.9 84.0988,-1023.9 84.0988,-1023.9 84.0988,-1023.9 84.0444,-1028.9 88.5986,-1023.95 83.99,-1033.9 83.99,-1033.9\"/>\n",
       "</g>\n",
       "<!-- sum0 -->\n",
       "<g id=\"node17\" class=\"node\"><title>sum0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"130.685,-1468 36.6846,-1468 36.6846,-1410 130.685,-1410 130.685,-1468\"/>\n",
       "<text text-anchor=\"middle\" x=\"83.6846\" y=\"-1435.3\" font-family=\"Times,serif\" font-size=\"14.00\">sum0</text>\n",
       "</g>\n",
       "<!-- sum0&#45;&gt;_minus1 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>sum0&#45;&gt;_minus1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M83.6846,-1399.43C83.6846,-1323.97 83.6846,-1158.39 83.6846,-1092.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.6846,-1409.89 79.1847,-1399.89 83.6846,-1404.89 83.6847,-1399.89 83.6847,-1399.89 83.6847,-1399.89 83.6846,-1404.89 88.1847,-1399.89 83.6846,-1409.89 83.6846,-1409.89\"/>\n",
       "</g>\n",
       "<!-- _mulscalar0 -->\n",
       "<g id=\"node18\" class=\"node\"><title>_mulscalar0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"130.685,-1562 36.6846,-1562 36.6846,-1504 130.685,-1504 130.685,-1562\"/>\n",
       "<text text-anchor=\"middle\" x=\"83.6846\" y=\"-1529.3\" font-family=\"Times,serif\" font-size=\"14.00\">_mulscalar0</text>\n",
       "</g>\n",
       "<!-- _mulscalar0&#45;&gt;sum0 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>_mulscalar0&#45;&gt;sum0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M83.6846,-1493.74C83.6846,-1485.2 83.6846,-1476.3 83.6846,-1468.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.6846,-1503.9 79.1847,-1493.9 83.6846,-1498.9 83.6847,-1493.9 83.6847,-1493.9 83.6847,-1493.9 83.6846,-1498.9 88.1847,-1493.9 83.6846,-1503.9 83.6846,-1503.9\"/>\n",
       "</g>\n",
       "<!-- random_normal0 -->\n",
       "<g id=\"node19\" class=\"node\"><title>random_normal0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"355.685,-622 261.685,-622 261.685,-564 355.685,-564 355.685,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">random_normal0</text>\n",
       "</g>\n",
       "<!-- _mul0 -->\n",
       "<g id=\"node20\" class=\"node\"><title>_mul0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"355.685,-716 261.685,-716 261.685,-658 355.685,-658 355.685,-716\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-683.3\" font-family=\"Times,serif\" font-size=\"14.00\">_mul0</text>\n",
       "</g>\n",
       "<!-- _mul0&#45;&gt;activation0 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>_mul0&#45;&gt;activation0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M252.219,-658.054C202.446,-638.573 186.355,-640.63 140.685,-622 137.766,-620.809 134.79,-619.529 131.807,-618.195\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.562,-661.805 250.606,-662.255 256.922,-659.942 252.282,-658.079 252.282,-658.079 252.282,-658.079 256.922,-659.942 253.959,-653.903 261.562,-661.805 261.562,-661.805\"/>\n",
       "</g>\n",
       "<!-- _mul0&#45;&gt;random_normal0 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>_mul0&#45;&gt;random_normal0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-647.744C308.685,-639.204 308.685,-630.298 308.685,-622.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-657.897 304.185,-647.897 308.685,-652.897 308.685,-647.897 308.685,-647.897 308.685,-647.897 308.685,-652.897 313.185,-647.897 308.685,-657.897 308.685,-657.897\"/>\n",
       "</g>\n",
       "<!-- _plus0 -->\n",
       "<g id=\"node21\" class=\"node\"><title>_plus0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"355.685,-810 261.685,-810 261.685,-752 355.685,-752 355.685,-810\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-777.3\" font-family=\"Times,serif\" font-size=\"14.00\">_plus0</text>\n",
       "</g>\n",
       "<!-- _plus0&#45;&gt;inf_mean_compute -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>_plus0&#45;&gt;inf_mean_compute</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.536,-745.378C254.835,-735.767 242.273,-725.448 231.073,-716.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.472,-751.897 263.889,-749.027 270.609,-748.723 266.745,-745.55 266.745,-745.55 266.745,-745.55 270.609,-748.723 269.601,-742.072 274.472,-751.897 274.472,-751.897\"/>\n",
       "</g>\n",
       "<!-- _plus0&#45;&gt;_mul0 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>_plus0&#45;&gt;_mul0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-741.744C308.685,-733.204 308.685,-724.298 308.685,-716.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-751.897 304.185,-741.897 308.685,-746.897 308.685,-741.897 308.685,-741.897 308.685,-741.897 308.685,-746.897 313.185,-741.897 308.685,-751.897 308.685,-751.897\"/>\n",
       "</g>\n",
       "<!-- gen_fc_0 -->\n",
       "<g id=\"node22\" class=\"node\"><title>gen_fc_0</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"355.685,-904 261.685,-904 261.685,-846 355.685,-846 355.685,-904\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-878.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-863.8\" font-family=\"Times,serif\" font-size=\"14.00\">200</text>\n",
       "</g>\n",
       "<!-- gen_fc_0&#45;&gt;_plus0 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>gen_fc_0&#45;&gt;_plus0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-835.744C308.685,-827.204 308.685,-818.298 308.685,-810.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-845.897 304.185,-835.897 308.685,-840.897 308.685,-835.897 308.685,-835.897 308.685,-835.897 308.685,-840.897 313.185,-835.897 308.685,-845.897 308.685,-845.897\"/>\n",
       "</g>\n",
       "<!-- gen_act_0 -->\n",
       "<g id=\"node23\" class=\"node\"><title>gen_act_0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"355.685,-998 261.685,-998 261.685,-940 355.685,-940 355.685,-998\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-972.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-957.8\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- gen_act_0&#45;&gt;gen_fc_0 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>gen_act_0&#45;&gt;gen_fc_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-929.744C308.685,-921.204 308.685,-912.298 308.685,-904.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-939.897 304.185,-929.897 308.685,-934.897 308.685,-929.897 308.685,-929.897 308.685,-929.897 308.685,-934.897 313.185,-929.897 308.685,-939.897 308.685,-939.897\"/>\n",
       "</g>\n",
       "<!-- gen_fc_1 -->\n",
       "<g id=\"node24\" class=\"node\"><title>gen_fc_1</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"355.685,-1092 261.685,-1092 261.685,-1034 355.685,-1034 355.685,-1092\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-1066.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-1051.8\" font-family=\"Times,serif\" font-size=\"14.00\">500</text>\n",
       "</g>\n",
       "<!-- gen_fc_1&#45;&gt;gen_act_0 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>gen_fc_1&#45;&gt;gen_act_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-1023.74C308.685,-1015.2 308.685,-1006.3 308.685,-998.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-1033.9 304.185,-1023.9 308.685,-1028.9 308.685,-1023.9 308.685,-1023.9 308.685,-1023.9 308.685,-1028.9 313.185,-1023.9 308.685,-1033.9 308.685,-1033.9\"/>\n",
       "</g>\n",
       "<!-- gen_act_1 -->\n",
       "<g id=\"node25\" class=\"node\"><title>gen_act_1</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"355.685,-1186 261.685,-1186 261.685,-1128 355.685,-1128 355.685,-1186\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-1160.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-1145.8\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- gen_act_1&#45;&gt;gen_fc_1 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>gen_act_1&#45;&gt;gen_fc_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-1117.74C308.685,-1109.2 308.685,-1100.3 308.685,-1092.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-1127.9 304.185,-1117.9 308.685,-1122.9 308.685,-1117.9 308.685,-1117.9 308.685,-1117.9 308.685,-1122.9 313.185,-1117.9 308.685,-1127.9 308.685,-1127.9\"/>\n",
       "</g>\n",
       "<!-- gen_fc_out -->\n",
       "<g id=\"node26\" class=\"node\"><title>gen_fc_out</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"355.685,-1280 261.685,-1280 261.685,-1222 355.685,-1222 355.685,-1280\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-1254.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"308.685\" y=\"-1239.8\" font-family=\"Times,serif\" font-size=\"14.00\">1568</text>\n",
       "</g>\n",
       "<!-- gen_fc_out&#45;&gt;gen_act_1 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>gen_fc_out&#45;&gt;gen_act_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.685,-1211.74C308.685,-1203.2 308.685,-1194.3 308.685,-1186.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.685,-1221.9 304.185,-1211.9 308.685,-1216.9 308.685,-1211.9 308.685,-1211.9 308.685,-1211.9 308.685,-1216.9 313.185,-1211.9 308.685,-1221.9 308.685,-1221.9\"/>\n",
       "</g>\n",
       "<!-- reshape0 -->\n",
       "<g id=\"node27\" class=\"node\"><title>reshape0</title>\n",
       "<polygon fill=\"#fdb462\" stroke=\"black\" points=\"354.685,-1374 260.685,-1374 260.685,-1316 354.685,-1316 354.685,-1374\"/>\n",
       "<text text-anchor=\"middle\" x=\"307.685\" y=\"-1341.3\" font-family=\"Times,serif\" font-size=\"14.00\">reshape0</text>\n",
       "</g>\n",
       "<!-- reshape0&#45;&gt;gen_fc_out -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>reshape0&#45;&gt;gen_fc_out</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.1,-1305.74C308.193,-1297.2 308.29,-1288.3 308.378,-1280.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.99,-1315.9 303.599,-1305.85 308.044,-1310.9 308.099,-1305.9 308.099,-1305.9 308.099,-1305.9 308.044,-1310.9 312.599,-1305.95 307.99,-1315.9 307.99,-1315.9\"/>\n",
       "</g>\n",
       "<!-- label -->\n",
       "<g id=\"node28\" class=\"node\"><title>label</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"195.685\" cy=\"-1063\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.685\" y=\"-1059.3\" font-family=\"Times,serif\" font-size=\"14.00\">label</text>\n",
       "</g>\n",
       "<!-- expand_dims0 -->\n",
       "<g id=\"node29\" class=\"node\"><title>expand_dims0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"242.685,-1186 148.685,-1186 148.685,-1128 242.685,-1128 242.685,-1186\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.685\" y=\"-1153.3\" font-family=\"Times,serif\" font-size=\"14.00\">expand_dims0</text>\n",
       "</g>\n",
       "<!-- expand_dims0&#45;&gt;label -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>expand_dims0&#45;&gt;label</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.685,-1117.74C195.685,-1109.2 195.685,-1100.3 195.685,-1092.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.685,-1127.9 191.185,-1117.9 195.685,-1122.9 195.685,-1117.9 195.685,-1117.9 195.685,-1117.9 195.685,-1122.9 200.185,-1117.9 195.685,-1127.9 195.685,-1127.9\"/>\n",
       "</g>\n",
       "<!-- _rminusscalar0 -->\n",
       "<g id=\"node30\" class=\"node\"><title>_rminusscalar0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"205.685,-1280 111.685,-1280 111.685,-1222 205.685,-1222 205.685,-1280\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.685\" y=\"-1247.3\" font-family=\"Times,serif\" font-size=\"14.00\">_rminusscalar0</text>\n",
       "</g>\n",
       "<!-- _rminusscalar0&#45;&gt;expand_dims0 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>_rminusscalar0&#45;&gt;expand_dims0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M173.731,-1212.59C177.268,-1203.79 180.98,-1194.56 184.324,-1186.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.987,-1221.9 169.543,-1210.94 171.853,-1217.26 173.718,-1212.62 173.718,-1212.62 173.718,-1212.62 171.853,-1217.26 177.893,-1214.3 169.987,-1221.9 169.987,-1221.9\"/>\n",
       "</g>\n",
       "<!-- concat0 -->\n",
       "<g id=\"node31\" class=\"node\"><title>concat0</title>\n",
       "<polygon fill=\"#fdb462\" stroke=\"black\" points=\"242.685,-1374 148.685,-1374 148.685,-1316 242.685,-1316 242.685,-1374\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.685\" y=\"-1341.3\" font-family=\"Times,serif\" font-size=\"14.00\">concat0</text>\n",
       "</g>\n",
       "<!-- concat0&#45;&gt;expand_dims0 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>concat0&#45;&gt;expand_dims0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.897,-1306.08C211.301,-1297.6 213.439,-1288.57 214.685,-1280 218.391,-1254.49 218.391,-1247.51 214.685,-1222 212.951,-1210.07 209.491,-1197.27 205.992,-1186.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"205.992,-1315.72 204.568,-1304.85 207.434,-1310.93 208.876,-1306.15 208.876,-1306.15 208.876,-1306.15 207.434,-1310.93 213.185,-1307.44 205.992,-1315.72 205.992,-1315.72\"/>\n",
       "</g>\n",
       "<!-- concat0&#45;&gt;_rminusscalar0 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>concat0&#45;&gt;_rminusscalar0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.638,-1306.59C177.101,-1297.79 173.389,-1288.56 170.045,-1280.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.382,-1315.9 176.476,-1308.3 182.517,-1311.26 180.651,-1306.62 180.651,-1306.62 180.651,-1306.62 182.517,-1311.26 184.826,-1304.94 184.382,-1315.9 184.382,-1315.9\"/>\n",
       "</g>\n",
       "<!-- _mul1 -->\n",
       "<g id=\"node32\" class=\"node\"><title>_mul1</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"242.685,-1468 148.685,-1468 148.685,-1410 242.685,-1410 242.685,-1468\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.685\" y=\"-1435.3\" font-family=\"Times,serif\" font-size=\"14.00\">_mul1</text>\n",
       "</g>\n",
       "<!-- _mul1&#45;&gt;reshape0 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>_mul1&#45;&gt;reshape0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.833,-1403.38C249.534,-1393.77 262.096,-1383.45 273.296,-1374.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.897,-1409.9 234.768,-1400.07 233.76,-1406.72 237.624,-1403.55 237.624,-1403.55 237.624,-1403.55 233.76,-1406.72 240.48,-1407.03 229.897,-1409.9 229.897,-1409.9\"/>\n",
       "</g>\n",
       "<!-- _mul1&#45;&gt;concat0 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>_mul1&#45;&gt;concat0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.685,-1399.74C195.685,-1391.2 195.685,-1382.3 195.685,-1374.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.685,-1409.9 191.185,-1399.9 195.685,-1404.9 195.685,-1399.9 195.685,-1399.9 195.685,-1399.9 195.685,-1404.9 200.185,-1399.9 195.685,-1409.9 195.685,-1409.9\"/>\n",
       "</g>\n",
       "<!-- sum1 -->\n",
       "<g id=\"node33\" class=\"node\"><title>sum1</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"242.685,-1562 148.685,-1562 148.685,-1504 242.685,-1504 242.685,-1562\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.685\" y=\"-1529.3\" font-family=\"Times,serif\" font-size=\"14.00\">sum1</text>\n",
       "</g>\n",
       "<!-- sum1&#45;&gt;_mul1 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>sum1&#45;&gt;_mul1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.685,-1493.74C195.685,-1485.2 195.685,-1476.3 195.685,-1468.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.685,-1503.9 191.185,-1493.9 195.685,-1498.9 195.685,-1493.9 195.685,-1493.9 195.685,-1493.9 195.685,-1498.9 200.185,-1493.9 195.685,-1503.9 195.685,-1503.9\"/>\n",
       "</g>\n",
       "<!-- _minus2 -->\n",
       "<g id=\"node34\" class=\"node\"><title>_minus2</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"186.685,-1656 92.6846,-1656 92.6846,-1598 186.685,-1598 186.685,-1656\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.685\" y=\"-1623.3\" font-family=\"Times,serif\" font-size=\"14.00\">_minus2</text>\n",
       "</g>\n",
       "<!-- _minus2&#45;&gt;_mulscalar0 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>_minus2&#45;&gt;_mulscalar0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.253,-1589.15C111.798,-1580.19 106.048,-1570.74 100.879,-1562.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.578,-1597.9 113.535,-1591.69 119.979,-1593.63 117.379,-1589.36 117.379,-1589.36 117.379,-1589.36 119.979,-1593.63 121.223,-1587.02 122.578,-1597.9 122.578,-1597.9\"/>\n",
       "</g>\n",
       "<!-- _minus2&#45;&gt;sum1 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>_minus2&#45;&gt;sum1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.116,-1589.15C167.572,-1580.19 173.321,-1570.74 178.49,-1562.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.791,-1597.9 158.146,-1587.02 159.39,-1593.63 161.99,-1589.36 161.99,-1589.36 161.99,-1589.36 159.39,-1593.63 165.834,-1591.69 156.791,-1597.9 156.791,-1597.9\"/>\n",
       "</g>\n",
       "<!-- makeloss0 -->\n",
       "<g id=\"node35\" class=\"node\"><title>makeloss0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"186.685,-1750 92.6846,-1750 92.6846,-1692 186.685,-1692 186.685,-1750\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.685\" y=\"-1717.3\" font-family=\"Times,serif\" font-size=\"14.00\">makeloss0</text>\n",
       "</g>\n",
       "<!-- makeloss0&#45;&gt;_minus2 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>makeloss0&#45;&gt;_minus2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.685,-1681.74C139.685,-1673.2 139.685,-1664.3 139.685,-1656.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.685,-1691.9 135.185,-1681.9 139.685,-1686.9 139.685,-1681.9 139.685,-1681.9 139.685,-1681.9 139.685,-1686.9 144.185,-1681.9 139.685,-1691.9 139.685,-1691.9\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1128b4b00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mx.sym.Variable(\"data\")\n",
    "label = mx.sym.Variable(\"label\")\n",
    "mx.viz.plot_network(vae.train(data, label))\n",
    "# Comment the line above and uncomment the one below if you want to save the VAE picture on disk\n",
    "#mx.viz.plot_network(vae.train(data, label), title=\"my_vae\", save_format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a VAE\n",
    "\n",
    "We are now set to train the VAE. In order to do so we have to define a data iterator and a module in mxnet. The data iterator takes care of batching the data while the module executes the computation graph and updates the model parameters. For the purpose of training the model, we only need the training data which we load from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:58:18 [INFO]: Reading ./binary_mnist/binary_mnist.train into memory\n",
      "10:58:51 [INFO]: ./binary_mnist/binary_mnist.train contains 50000 data points\n"
     ]
    }
   ],
   "source": [
    "mnist = {}\n",
    "file_name = join(data_dir, \"binary_mnist.{}\".format(TRAIN_SET))\n",
    "logging.info(\"Reading {} into memory\".format(file_name))\n",
    "mnist[TRAIN_SET] = mx.nd.array(genfromtxt(file_name))\n",
    "logging.info(\"{} contains {} data points\".format(file_name, mnist[TRAIN_SET].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that data we define the training set iterator. At this point we also need to choose a batch_size that will then be used in training. Notice that we randomise the order in which the data points are presented in the training set. It is important that `data_name` and `label_name` match the names of the unbound variables in our model. Mxnet will use this information to pass the correct data points to the variables. Finally, notice that the data and labels are identical. This is because the VAE tries to reconstruct its input data and thus labels and data are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(data=mnist[TRAIN_SET], data_name=\"data\", label=mnist[TRAIN_SET], label_name=\"label\",\n",
    "                                   batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a module that will do the training for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mx' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8e28988b1087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vae_module = mx.module.Module(vae.train(data=mx.sym.Variable(\"data\"), label=mx.sym.Variable(\"label\")),\n\u001b[0m\u001b[1;32m      2\u001b[0m                            \u001b[0mdata_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovide_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            label_names=[train_iter.provide_label[0][0]], context=ctx, logger=logging)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mx' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "vae_module = mx.module.Module(vae.train(data=mx.sym.Variable(\"data\"), label=mx.sym.Variable(\"label\")),\n",
    "                           data_names=[train_iter.provide_data[0][0]],\n",
    "                           label_names=[train_iter.provide_label[0][0]], context=ctx, logger=logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the vae (or any other network defined in mxnet) is most easily done using the fit method. Here we choose to train our model for 20 epochs. Our optimiser will be adam. Training will take some time (2-5 minutes depending on your machine). We are keeping track of the loss (the negative ELBO) to see how the model develops. Notice that this loss\n",
    "is not the actual negative ELBO but a _doubly stochastic approximation_ to it (see [here](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586) and [here](http://proceedings.mlr.press/v32/titsias14.pdf)). The two sources of stochasticity are the mini-batches (the ELBO is defined with respect to the entire data set) and the reparametrisation trick (we approximate the integral over $ z $ through sampling). Both sources of stochasticity leave the approximation unbiased, however. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "optimiser = \"adam\"\n",
    "\n",
    "vae_module.fit(train_data=train_iter, optimizer=optimiser, force_init=True, force_rebind=True, num_epoch=epochs,\n",
    "               optimizer_params={'learning_rate': DEFAULT_LEARNING_RATE},\n",
    "               batch_end_callback=mx.callback.Speedometer(frequent=20, batch_size=batch_size),\n",
    "               epoch_end_callback=mx.callback.do_checkpoint('vae'),\n",
    "               eval_metric=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
